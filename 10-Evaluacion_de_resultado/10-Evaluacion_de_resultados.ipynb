{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bfdab0-3087-401b-b436-c381ba241968",
   "metadata": {},
   "source": [
    "# Evaluacion de resultados\n",
    "\n",
    "En este notebook se muestran para la evaluacion de los resultados de una prediccion con un algoritmo de Machine Learning.\n",
    "\n",
    "\n",
    "## DataSet\n",
    "\n",
    "### Descripcion:\n",
    "\n",
    "NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods. Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "### Ficheros de datos\n",
    "\n",
    "* <span style=\"color:green\"> **KDDTrain+.ARFF**: The full NSL-KDD train set with binary labels in ARFF format </span>\n",
    "* KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format </span>\n",
    "* KDDTrain+_20Percent.ARFF: A 20% subset of the KDDTrain+.arff file \n",
    "* KDDTrain+_20Percent.TXT: A 20% subset of the KDDTrain+.txt file \n",
    "* KDDTest+.ARFF: The full NSL-KDD test set with binary labels in ARFF format\n",
    "* KDDTest+.TXT: The full NSL-KDD test set including attack-type labels and difficulty level in CSV format \n",
    "* KDDTest-21.ARFF: A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21 \n",
    "* KDDTest-21.TXT: A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ca5e3-5bb7-4fc4-b053-0bdc60764b9a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ae4933-439e-4739-8ec9-37f6fc14792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b8108-4fef-4f36-b083-487546b1c5fa",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10741955-c82f-456b-9ad7-49eaa0310e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura del DataSet NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns = attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3485a518-ab2d-40c3-9254-c723b554a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de una funcion que realice el particionado completo\n",
    "def train_val_test_split(df, rsate = 42, shuffle = True, stratify = None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size = 0.4, random_state = rsate, shuffle = shuffle, stratify = strat  \n",
    "    )\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size = 0.5, random_state = rsate, shuffle = shuffle, stratify = strat\n",
    "    )\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3ae76e-ef68-437e-b314-3c68b075c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de un pipeline para los atributos numericos\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = \"median\")),\n",
    "    ('rbst_scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d463a01-48dc-4d8d-bf68-cad4efa640fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador para codificar unicamente las columnas categoricas y devolver un DataFrame\n",
    "class CustomOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._oh = OneHotEncoder(sparse = False)\n",
    "        self.columns = None\n",
    "    def fit(self, X, y = None):\n",
    "        X_cat = X.select_dtypes(include = ['object'])\n",
    "        self._columns = pd.get_dummies(X_cat).colums\n",
    "        self._oh.fit(X_cat)\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        X_copy = X.copy()\n",
    "        X_cat = X_copy.select_dtypes(include = ['object'])\n",
    "        X_num = X_copy.select_dtypes(exclude = ['object'])\n",
    "        X_cat_oh = self.oh.transform(X_cat)\n",
    "        X_cat_oh = pd.DataFrame(X_cat_oh, columns = self._columns, index = X_copy.index)\n",
    "        X_copy.drop(list(X_cat), axis = 1, inplace = True)\n",
    "        return X_copy.join(X_cat_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0a0ca2-cbfe-4abf-b8a4-d5e5718c4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador que prepara todo el DataSet llamado Pipelines y transformadores personalizados\n",
    "class DataFramePreparer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._full_pipeline = None\n",
    "        self._columns = None\n",
    "    def fit(self, X, y = None):\n",
    "        num_attribs = list(X.select_dtypes(exclude = ['object']))\n",
    "        cat_attribs = list(X.select_dtypes(include = ['object']))\n",
    "        self._full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attribs),\n",
    "            (\"cat\", CustomOneHotEncoder(), cat_attribs),\n",
    "        ])\n",
    "        self._full_pipeline.fit(X)\n",
    "        self._columns = pd.get_dummies(X).columns\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        X_copy = X.copy()\n",
    "        X_prep = self._full_pipeline.transform(X_copy)\n",
    "        return pd.DataFrame(X_prep, columns = self._columns, index = X_copy.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad7db08-38de-4d08-ae36-7a9c7d63544d",
   "metadata": {},
   "source": [
    "### Lectura del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd07c3e-7425-43e0-a322-b374355e2fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232.0</td>\n",
       "      <td>8153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>remote_job</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type     service flag  src_bytes  dst_bytes land  \\\n",
       "0       0.0           tcp    ftp_data   SF      491.0        0.0    0   \n",
       "1       0.0           udp       other   SF      146.0        0.0    0   \n",
       "2       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "3       0.0           tcp        http   SF      232.0     8153.0    0   \n",
       "4       0.0           tcp        http   SF      199.0      420.0    0   \n",
       "5       0.0           tcp     private  REJ        0.0        0.0    0   \n",
       "6       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "7       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "8       0.0           tcp  remote_job   S0        0.0        0.0    0   \n",
       "9       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0             0.0     0.0  0.0  ...                25.0   \n",
       "1             0.0     0.0  0.0  ...                 1.0   \n",
       "2             0.0     0.0  0.0  ...                26.0   \n",
       "3             0.0     0.0  0.0  ...               255.0   \n",
       "4             0.0     0.0  0.0  ...               255.0   \n",
       "5             0.0     0.0  0.0  ...                19.0   \n",
       "6             0.0     0.0  0.0  ...                 9.0   \n",
       "7             0.0     0.0  0.0  ...                15.0   \n",
       "8             0.0     0.0  0.0  ...                23.0   \n",
       "9             0.0     0.0  0.0  ...                13.0   \n",
       "\n",
       "  dst_host_same_srv_rate  dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                   0.17                    0.03                         0.17   \n",
       "1                   0.00                    0.60                         0.88   \n",
       "2                   0.10                    0.05                         0.00   \n",
       "3                   1.00                    0.00                         0.03   \n",
       "4                   1.00                    0.00                         0.00   \n",
       "5                   0.07                    0.07                         0.00   \n",
       "6                   0.04                    0.05                         0.00   \n",
       "7                   0.06                    0.07                         0.00   \n",
       "8                   0.09                    0.05                         0.00   \n",
       "9                   0.05                    0.06                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "5                         0.00                  0.00   \n",
       "6                         0.00                  1.00   \n",
       "7                         0.00                  1.00   \n",
       "8                         0.00                  1.00   \n",
       "9                         0.00                  1.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "5                      0.00                  1.00                      1.00   \n",
       "6                      1.00                  0.00                      0.00   \n",
       "7                      1.00                  0.00                      0.00   \n",
       "8                      1.00                  0.00                      0.00   \n",
       "9                      1.00                  0.00                      0.00   \n",
       "\n",
       "     class  \n",
       "0   normal  \n",
       "1   normal  \n",
       "2  anomaly  \n",
       "3   normal  \n",
       "4   normal  \n",
       "5  anomaly  \n",
       "6  anomaly  \n",
       "7  anomaly  \n",
       "8  anomaly  \n",
       "9  anomaly  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_kdd_dataset(\"../datasets/NSL-KDD/KDDTrain+.arff\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88ad2c-d5e7-4f6a-9866-5de758202506",
   "metadata": {},
   "source": [
    "## Division del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bf25e22-2714-4083-aa6d-0db2a6eb7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division del DataSet en los diferentes SubConjuntos\n",
    "train_set, val_set, test_set = train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e06b122d-71b6-4d44-838f-0c12c7f736c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del Training Set:  75583\n",
      "Longitud del Validation Set:  25195\n",
      "Longitud del Test Set:  25195\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del Training Set: \", len(train_set))\n",
    "print(\"Longitud del Validation Set: \", len(val_set))\n",
    "print(\"Longitud del Test Set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ccae5e-3eb7-4fb9-a77b-51e313941a2a",
   "metadata": {},
   "source": [
    "Para cada uno de los subconjuntos, se separa las etiquetas de las caracteristicas de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ab9d3ec-b876-47bc-b2a8-33388d74b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet General\n",
    "X_df = df.drop(\"class\", axis = 1)\n",
    "y_df = df[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e455a7c-c333-4242-91c4-024832769b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet de entrenamiento\n",
    "X_train = train_set.drop(\"class\", axis = 1)\n",
    "y_train = train_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da3fc933-4454-427f-8d6e-03fa47aa0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet de Validacion\n",
    "X_val = val_set.drop(\"class\", axis = 1)\n",
    "y_val = val_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265edc8-bb4d-4690-a2c0-5e8320521844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
